{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate the use of RNN model in text classification\n",
    "---\n",
    "\n",
    "Some of the codes are token from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/skflow/text_classification_builtin_rnn_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import pandas\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1785, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series_summary</th>\n",
       "      <th>Series_title</th>\n",
       "      <th>label</th>\n",
       "      <th>label_code</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSE1001</th>\n",
       "      <td>Sprague-Dawley rat retina post-injury and cont...</td>\n",
       "      <td>retina injury timecourse</td>\n",
       "      <td>dz</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE10064</th>\n",
       "      <td>This study aims to determine if global gene ex...</td>\n",
       "      <td>Gene expression in immortalized B-lymphocytes ...</td>\n",
       "      <td>dz</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE10082</th>\n",
       "      <td>Conventional biochemical and molecular techniq...</td>\n",
       "      <td>Aryl Hydrocarbon Receptor Regulates Distinct D...</td>\n",
       "      <td>gene</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE1009</th>\n",
       "      <td>Gene expression profiling in glomeruli from hu...</td>\n",
       "      <td>Diabetic nephropathy</td>\n",
       "      <td>dz</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE1010</th>\n",
       "      <td>RNA samples prepared from lymphoblastic cells ...</td>\n",
       "      <td>FCHL study</td>\n",
       "      <td>dz</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Series_summary  \\\n",
       "id                                                            \n",
       "GSE1001   Sprague-Dawley rat retina post-injury and cont...   \n",
       "GSE10064  This study aims to determine if global gene ex...   \n",
       "GSE10082  Conventional biochemical and molecular techniq...   \n",
       "GSE1009   Gene expression profiling in glomeruli from hu...   \n",
       "GSE1010   RNA samples prepared from lymphoblastic cells ...   \n",
       "\n",
       "                                               Series_title label  label_code  \\\n",
       "id                                                                              \n",
       "GSE1001                            retina injury timecourse    dz           1   \n",
       "GSE10064  Gene expression in immortalized B-lymphocytes ...    dz           1   \n",
       "GSE10082  Aryl Hydrocarbon Receptor Regulates Distinct D...  gene           2   \n",
       "GSE1009                                Diabetic nephropathy    dz           1   \n",
       "GSE1010                                          FCHL study    dz           1   \n",
       "\n",
       "          split  \n",
       "id               \n",
       "GSE1001       0  \n",
       "GSE10064      0  \n",
       "GSE10082      0  \n",
       "GSE1009       0  \n",
       "GSE1010       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Training data\n",
    "# load the labeled df\n",
    "df_labeled = pd.read_csv('data/Labeled_GSEs_texts_with_labels.csv').set_index('id')\n",
    "df_labeled = df_labeled.fillna('')\n",
    "print df_labeled.shape\n",
    "df_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1785, 100)\n",
      "Total words: 19474\n"
     ]
    }
   ],
   "source": [
    "### Process vocabulary\n",
    "\n",
    "MAX_DOCUMENT_LENGTH = 100\n",
    "\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH)\n",
    "\n",
    "X = np.array(list(vocab_processor.fit_transform(df_labeled['Series_summary'])))\n",
    "print X.shape\n",
    "\n",
    "n_words = len(vocab_processor.vocabulary_)\n",
    "print 'Total words: %d' % n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Models\n",
    "\n",
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "# Customized function to transform batched X into embeddings\n",
    "def input_op_fn(X):\n",
    "    # Convert indexes of words into embeddings.\n",
    "    # This creates embeddings matrix of [n_words, EMBEDDING_SIZE] and then\n",
    "    # maps word indexes of the sequence into [batch_size, sequence_length,\n",
    "    # EMBEDDING_SIZE].\n",
    "    word_vectors = learn.ops.categorical_variable(X, n_classes=n_words,\n",
    "        embedding_size=EMBEDDING_SIZE, name='words')\n",
    "    # Split into list of embedding per word, while removing doc length dim.\n",
    "    # word_list results to be a list of tensors [batch_size, EMBEDDING_SIZE].\n",
    "    word_list = learn.ops.split_squeeze(1, MAX_DOCUMENT_LENGTH, word_vectors)\n",
    "    return word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split train, test\n",
    "splits = df_labeled['split']\n",
    "y = df_labeled['label_code'].values\n",
    "\n",
    "train_idx = np.where(splits != 0)[0]\n",
    "valid_idx = np.where(splits == 0)[0]\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_test, y_test = X[valid_idx], y[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #100, epoch #2, avg. train loss: 0.69750\n",
      "Step #200, epoch #5, avg. train loss: 0.07701\n",
      "Accuracy: 0.748322\n"
     ]
    }
   ],
   "source": [
    "# Single direction GRU with a single layer\n",
    "classifier = learn.TensorFlowRNNClassifier(rnn_size=EMBEDDING_SIZE, \n",
    "    n_classes=3, cell_type='gru', input_op_fn=input_op_fn,\n",
    "    num_layers=1, bidirectional=False, sequence_length=None,\n",
    "    steps=200, optimizer='Adam', learning_rate=0.01, continue_training=True)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "score = metrics.accuracy_score(y_test, classifier.predict(X_test))\n",
    "print('Accuracy: {0:f}'.format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #100, epoch #2, avg. train loss: 0.69750\n",
      "Step #200, epoch #5, avg. train loss: 0.07701\n",
      "Step #300, epoch #7, avg. train loss: 0.02212\n",
      "Step #400, epoch #10, avg. train loss: 0.01688\n",
      "Step #500, epoch #13, avg. train loss: 0.02350\n",
      "Accuracy: 0.775168\n"
     ]
    }
   ],
   "source": [
    "# Single direction GRU with a single layer\n",
    "classifier = learn.TensorFlowRNNClassifier(rnn_size=EMBEDDING_SIZE, \n",
    "    n_classes=3, cell_type='gru', input_op_fn=input_op_fn,\n",
    "    num_layers=1, bidirectional=False, sequence_length=None,\n",
    "    steps=500, optimizer='Adam', learning_rate=0.01, continue_training=True)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "score = metrics.accuracy_score(y_test, classifier.predict(X_test))\n",
    "print('Accuracy: {0:f}'.format(score))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
